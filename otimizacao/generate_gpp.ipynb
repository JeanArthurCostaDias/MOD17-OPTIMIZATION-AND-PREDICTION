{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mod17 import MOD17\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santarem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "observacoes_santarem = pd.read_csv('dados/Ameriflux/santarem/FLX_BR-Sa1_FLUXNET2015_FULLSET_DD_2002-2011_1-4.csv', na_values=-9999)\n",
    "observacoes_santarem.index = observacoes_santarem['TIMESTAMP'].apply(lambda x:datetime.strptime(str(x), '%Y%m%d'))\n",
    "observacoes_santarem = observacoes_santarem[\"GPP_DT_VUT_REF\"].dropna()\n",
    "observacoes_santarem = observacoes_santarem.rename_axis('index')\n",
    "observacoes_santarem = observacoes_santarem.rename('GPP')\n",
    "observacoes_santarem.to_csv('dados_calculados_torres/observacoes_santarem_diario.csv')\n",
    "\n",
    "sant_8D_2002 = observacoes_santarem['2002'].resample('8D').sum()\n",
    "sant_8D_2003 = observacoes_santarem['2003'].resample('8D').sum()\n",
    "sant_8D_2004 = observacoes_santarem['2004'].resample('8D').sum()\n",
    "sant_8D_2005 = observacoes_santarem['2005'].resample('8D').sum()\n",
    "sant_8D_2006 = observacoes_santarem['2006'].resample('8D').sum()\n",
    "sant_8D_2008 = observacoes_santarem['2008'].resample('8D').sum()\n",
    "sant_8D_2009 = observacoes_santarem['2009'].resample('8D').sum()\n",
    "sant_8D_2010 = observacoes_santarem['2010'].resample('8D').sum()\n",
    "sant_8D_2011 = observacoes_santarem['2011'].resample('8D').sum()\n",
    "\n",
    "observacoes_santarem = pd.concat([sant_8D_2002, sant_8D_2003,\n",
    "                                  sant_8D_2004, sant_8D_2005,\n",
    "                                  sant_8D_2006, sant_8D_2008,\n",
    "                                  sant_8D_2009, sant_8D_2010, sant_8D_2011], axis=0)\n",
    "\n",
    "observacoes_santarem.to_csv('dados_calculados_torres/observacoes_santarem.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "Gpp_mod = pd.read_csv('dados/MODIS/GPP/Santarem_GPP.csv', header=None,na_values='F') # unidade: (%)\n",
    "Gpp_mod.index = Gpp_mod[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "Gpp_mod = Gpp_mod.drop([0,1,2,3,4], axis=1)\n",
    "Gpp_mod.columns = range(len(Gpp_mod.columns))\n",
    "Gpp_mod = Gpp_mod[144].to_frame().rename(columns={144:'Gpp_modis'})\n",
    "sant_gpp_mod = Gpp_mod['2002':'2011'] * 0.0001 * 1000\n",
    "mod17_sant = sant_gpp_mod['Gpp_modis']\n",
    "mod17_sant = pd.concat([mod17_sant['2002':'2006'] ,mod17_sant['2008':'2011']], axis=0)\n",
    "mod17_sant = mod17_sant.rename_axis('index')\n",
    "mod17_sant = mod17_sant.rename('GPP')\n",
    "mod17_sant.to_csv('dados_calculados_torres/gpp_modis_santarem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alan Breno\\AppData\\Local\\Temp\\ipykernel_12128\\3213685025.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps1['PS'] = pd.to_numeric(ps1['PS'])\n",
      "C:\\Users\\Alan Breno\\AppData\\Local\\Temp\\ipykernel_12128\\3213685025.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps2['PS'] = pd.to_numeric(ps2['PS'])\n"
     ]
    }
   ],
   "source": [
    "def constructor_2(path):\n",
    "    nome = path.split('/')[1].split('_')[0]\n",
    "    df = pd.read_csv(path, parse_dates=['date'])\n",
    "    df = df.rename({'albedo':nome},axis=1)\n",
    "    # Definindo a coluna 'system:time_start' como índice\n",
    "    hora_inicio = df['date'].min().floor('d')\n",
    "    df.index = hora_inicio + pd.to_timedelta(df.index, unit='h')\n",
    "    # Removendo a coluna 'system:time_start'\n",
    "    df = df.drop(['date','.geo'], axis=1)\n",
    "    df = df.drop('system:index',axis=1)\n",
    "    return df\n",
    "\n",
    "# Leitura e pré-processamento dos dados de temperatura\n",
    "tday = constructor_2('dados/Merra/santarem/st_t10m.csv') - 273.15 #( K° -> C°)\n",
    "tday1 = tday['2002':'2006']\n",
    "tday2 = tday['2008':'2011']\n",
    "tday = pd.concat([tday['2002':'2006'],tday['2008':'2011']], axis=0)\n",
    "tmin1 = tday1['T10M'].resample('D').min().values  # Reamostrando para Temperatura mínima diária\n",
    "tmin2 = tday2['T10M'].resample('D').min().values  # Reamostrando para Temperatura mínima diária\n",
    "tmin = np.concatenate([tmin1,tmin2])\n",
    "tmean_caxiuana = tday['T10M'].resample('D').mean().values  # Temperatura média diária\n",
    "tmean_vpd1 = tday1['T10M'].between_time('10:00', '22:00').resample('D').mean().values\n",
    "tmean_vpd2 = tday2['T10M'].between_time('10:00', '22:00').resample('D').mean().values\n",
    "tmean_vpd = np.concatenate([tmean_vpd1,tmean_vpd2])\n",
    "\n",
    "# Leitura e pré-processamento dos dados de razão de mistura de vapor de água\n",
    "qv10m = constructor_2('dados/Merra/santarem/st_qv10m.csv') # unidade: \"Mass fraction\" (kg/kg)\n",
    "qv10m1 = qv10m['2002':'2006']\n",
    "qv10m2 = qv10m['2008':'2011']\n",
    "qv10m1 = pd.to_numeric(qv10m1['QV10M']).between_time('10:00', '22:00').resample('D').mean().values\n",
    "qv10m2 = pd.to_numeric(qv10m2['QV10M']).between_time('10:00', '22:00').resample('D').mean().values\n",
    "qv10m = np.concatenate([qv10m1, qv10m2])\n",
    "\n",
    "# Leitura e pré-processamento dos dados de pressão atmosférica\n",
    "ps = constructor_2('dados/Merra/santarem/st_ps.csv') # unidade: Pa  # Removendo vírgulas dos valores\n",
    "ps1 = ps['2002':'2006']\n",
    "ps2 = ps['2008':'2011']\n",
    "ps1['PS'] = pd.to_numeric(ps1['PS'])\n",
    "ps2['PS'] = pd.to_numeric(ps2['PS'])\n",
    "ps1 = ps1.between_time('10:00', '22:00').resample('D').mean()\n",
    "ps2 = ps2.between_time('10:00', '22:00').resample('D').mean()\n",
    "ps1 = pd.to_numeric(ps1['PS']).values\n",
    "ps2 = pd.to_numeric(ps2['PS']).values\n",
    "ps = np.concatenate([ps1,ps2])\n",
    "\n",
    "# Leitura e pré-processamento dos dados de radiação solar incidente\n",
    "SWGNT = constructor_2('dados/Merra/santarem/st_swgnt.csv')\n",
    "SWGNT1 = SWGNT['2002':'2006']\n",
    "SWGNT2 = SWGNT['2008':'2011']\n",
    "SWGNT1 = SWGNT1['SWGNT'].resample('D').mean().values # unidade: W/m^2\n",
    "SWGNT2 = SWGNT2['SWGNT'].resample('D').mean().values # unidade: W/m^2\n",
    "SWGNT = np.concatenate([SWGNT1,SWGNT2])\n",
    "\n",
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "# Leitura e pré-processamento dos dados de Fração de Absorção de Luz Fotossinteticamente Ativa (FPAR)\n",
    "fpar = pd.read_csv('dados/Merra/santarem/st_fpar.csv', header=None,na_values='F') # unidade: (%)\n",
    "fpar.index = fpar[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "fpar = fpar.drop([0,1,2,3,4], axis=1)\n",
    "fpar.columns = range(len(fpar.columns))\n",
    "fpar = fpar[144]\n",
    "\n",
    "# ================================\n",
    "\n",
    "# Tratamento de dados faltando usando interpolação linear (8 dias -> diário)\n",
    "fpar = pd.concat([fpar.resample('D').interpolate('linear')['2002':'2006'], fpar.resample('D').interpolate('linear')['2008':'2011']], axis=0)\n",
    "fpar = fpar.values\n",
    "\n",
    "\n",
    "drivers_santarem = [\n",
    "    fpar[:][...,None],\n",
    "    tmin[:][...,None],\n",
    "    MOD17.vpd(qv10m, ps, tmean_vpd)[...,None],\n",
    "    MOD17.par(SWGNT)[:][...,None]\n",
    "]\n",
    "drivers_santarem[2] = np.where(drivers_santarem[2] < 0, 0, drivers_santarem[2]) # VPD < 0 = 0\n",
    "\n",
    "# Gerando GPP a partir dos dados do bioma \"Evergreen Broadleaf Forest\" como parâmetro diretamente\n",
    "parametros = pd.read_csv('mod17_bplut/MOD17_BPLUT_CX.X_MERRA_NASA.csv')['EBF=1'].values\n",
    "\n",
    "parametros = [0.001405, -8.0, 9.09, 1000.0, 4000.0, 26.9, 2.0, 2.0, 1.1, 0.162, 0.00604, 0.00519, 0.00397] # Igual ao acima\n",
    "\n",
    "gpp = MOD17._gpp(parametros,drivers_santarem[0],drivers_santarem[1],drivers_santarem[2],drivers_santarem[3])\n",
    "\n",
    "index_santarem = pd.date_range(start='2002-01-01', end='2006-12-31', freq='D')\n",
    "index_santarem = index_santarem.union(pd.date_range(start='2008-01-01', end='2011-12-31', freq='D'))\n",
    "\n",
    "gpp_santarem = pd.DataFrame(gpp, index=index_santarem)\n",
    "\n",
    "gpp_santarem = gpp_santarem.rename_axis('index')\n",
    "gpp_santarem = gpp_santarem[0].rename('GPP')\n",
    "\n",
    "gpp_santarem.to_csv('dados_calculados_torres/gpp_algpad_santarem_diario.csv')\n",
    "\n",
    "np.save('dados_calculados_torres/drivers_santarem', drivers_santarem)\n",
    "\n",
    "sant_8D_2002 = gpp_santarem['2002'].resample('8D').sum()\n",
    "sant_8D_2003 = gpp_santarem['2003'].resample('8D').sum()\n",
    "sant_8D_2004 = gpp_santarem['2004'].resample('8D').sum()\n",
    "sant_8D_2005 = gpp_santarem['2005'].resample('8D').sum()\n",
    "sant_8D_2006 = gpp_santarem['2006'].resample('8D').sum()\n",
    "sant_8D_2008 = gpp_santarem['2008'].resample('8D').sum()\n",
    "sant_8D_2009 = gpp_santarem['2009'].resample('8D').sum()\n",
    "sant_8D_2010 = gpp_santarem['2010'].resample('8D').sum()\n",
    "sant_8D_2011 = gpp_santarem['2011'].resample('8D').sum()\n",
    "\n",
    "gpp_santarem = pd.concat([sant_8D_2002, sant_8D_2003,\n",
    "                            sant_8D_2004, sant_8D_2005,\n",
    "                            sant_8D_2006, sant_8D_2008,\n",
    "                            sant_8D_2009, sant_8D_2010, sant_8D_2011], axis=0)\n",
    "\n",
    "gpp_santarem.to_csv('dados_calculados_torres/gpp_algpad_santarem.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drivers_santarem = np.load('dados_calculados_torres/drivers_santarem.npy')\n",
    "dict = {'1': np.squeeze(drivers_santarem[0]), '2': np.squeeze(drivers_santarem[1]), '3': np.squeeze(drivers_santarem[2]), '4': np.squeeze(drivers_santarem[3])} \n",
    "df_drivers_santarem = pd.DataFrame(dict, index=index_santarem)\n",
    "\n",
    "drivers_santarem_mes = []\n",
    "for i in range(12):\n",
    "    mes = df_drivers_santarem[df_drivers_santarem.index.month == i+1].to_numpy().T\n",
    "    drivers_santarem_mes.append(mes)\n",
    "\n",
    "np.savez('dados_calculados_torres/drivers_santarem_mes',    drivers_santarem_mes[0], \n",
    "                                                            drivers_santarem_mes[1],\n",
    "                                                            drivers_santarem_mes[2],\n",
    "                                                            drivers_santarem_mes[3],\n",
    "                                                            drivers_santarem_mes[4],\n",
    "                                                            drivers_santarem_mes[5],\n",
    "                                                            drivers_santarem_mes[6],\n",
    "                                                            drivers_santarem_mes[7],\n",
    "                                                            drivers_santarem_mes[8],\n",
    "                                                            drivers_santarem_mes[9],\n",
    "                                                            drivers_santarem_mes[10],\n",
    "                                                            drivers_santarem_mes[11])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "observacoes_peru = pd.read_csv('dados/Ameriflux/amazonia_peruana/AMF_PE-QFR_FLUXNET_FULLSET_DD_2018-2019_3-5.csv')\n",
    "observacoes_peru.index = observacoes_peru['TIMESTAMP'].apply(lambda x:datetime.strptime(str(x), '%Y%m%d'))\n",
    "observacoes_peru = observacoes_peru['GPP_DT_VUT_REF'].dropna()\n",
    "observacoes_peru = observacoes_peru.rename_axis('index')\n",
    "observacoes_peru = observacoes_peru.rename('GPP')\n",
    "observacoes_peru.to_csv('dados_calculados_torres/observacoes_peru_diario.csv')\n",
    "\n",
    "peru_2018 = observacoes_peru['2018'].resample('8D').sum()\n",
    "peru_2019 = observacoes_peru['2019'].resample('8D').sum()\n",
    "\n",
    "observacoes_peru = pd.concat([peru_2018, peru_2019], axis=0)\n",
    "\n",
    "observacoes_peru.to_csv('dados_calculados_torres/observacoes_peru.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "Gpp_mod = pd.read_csv('dados/MODIS/GPP/Peru_GPP.csv', header=None,na_values='F') # unidade: (%)\n",
    "Gpp_mod.index = Gpp_mod[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "Gpp_mod = Gpp_mod.drop([0,1,2,3,4], axis=1)\n",
    "Gpp_mod.columns = range(len(Gpp_mod.columns))\n",
    "Gpp_mod = Gpp_mod[144].to_frame().rename(columns={144:'Gpp_modis'})\n",
    "peru_gpp_mod = Gpp_mod['2018':'2019'] * 0.0001 * 1000\n",
    "mod17_peru = peru_gpp_mod['Gpp_modis']\n",
    "mod17_peru = mod17_peru.rename_axis('index')\n",
    "mod17_peru = mod17_peru.rename('GPP')\n",
    "\n",
    "mod17_peru.to_csv('dados_calculados_torres/gpp_modis_peru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor_2(path):\n",
    "    nome = path.split('/')[1].split('_')[0]\n",
    "    df = pd.read_csv(path, parse_dates=['date'])\n",
    "    df = df.rename({'albedo':nome},axis=1)\n",
    "    # Definindo a coluna 'system:time_start' como índice\n",
    "    hora_inicio = df['date'].min().floor('d')\n",
    "    df.index = hora_inicio + pd.to_timedelta(df.index, unit='h')\n",
    "    # Removendo a coluna 'system:time_start'\n",
    "    df = df.drop(['date','.geo'], axis=1)\n",
    "    df = df.drop('system:index',axis=1)\n",
    "    return df\n",
    "\n",
    "# Leitura e pré-processamento dos dados de temperatura\n",
    "tday = constructor_2('dados/Merra/amazonia peruana/pe_t10m.csv') - 273.15 #( K° -> C°)\n",
    "tday = tday['2018':'2019']\n",
    "tmin = tday['T10M'].resample('D').min().values  # Reamostrando para Temperatura mínima diária\n",
    "tmean_peru = tday['T10M'].resample('D').mean().values  # Temperatura média diária\n",
    "tmean_vpd = tday['T10M'].between_time('10:00', '22:00').resample('D').mean().values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de razão de mistura de vapor de água\n",
    "qv10m = constructor_2('dados/Merra/amazonia peruana/pe_qv10m.csv') # unidade: \"Mass fraction\" (kg/kg)\n",
    "qv10m = qv10m['2018':'2019']\n",
    "qv10m = pd.to_numeric(qv10m['QV10M']).between_time('10:00', '22:00').resample('D').mean().values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de pressão atmosférica\n",
    "ps = constructor_2('dados/Merra/amazonia peruana/pe_ps.csv') # unidade: Pa  # Removendo vírgulas dos valores\n",
    "ps = ps['2018':'2019']\n",
    "ps['PS'] = pd.to_numeric(ps['PS'])\n",
    "ps = ps.between_time('10:00', '22:00').resample('D').mean()\n",
    "ps = pd.to_numeric(ps['PS']).values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de radiação solar incidente\n",
    "SWGNT = constructor_2('dados/Merra/amazonia peruana/pe_swgnt.csv')\n",
    "SWGNT = SWGNT['2018':'2019']\n",
    "SWGNT = SWGNT['SWGNT'].resample('D').mean().values # unidade: W/m^2\n",
    "\n",
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "# Leitura e pré-processamento dos dados de Fração de Absorção de Luz Fotossinteticamente Ativa (FPAR)\n",
    "fpar = pd.read_csv('dados/Merra/amazonia peruana/pe_fpar.csv', header=None,na_values='F') # unidade: (%)\n",
    "fpar.index = fpar[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "fpar = fpar.drop([0,1,2,3,4], axis=1)\n",
    "fpar.columns = range(len(fpar.columns))\n",
    "fpar = fpar[144]\n",
    "\n",
    "# ================================\n",
    "\n",
    "# Tratamento de dados faltando usando interpolação linear (8 dias -> diário)\n",
    "fpar = fpar.resample('D').interpolate('linear')['2018':'2019']\n",
    "\n",
    "fpar = fpar.values\n",
    "\n",
    "drivers_peru = [\n",
    "    fpar[:][...,None],\n",
    "    tmin[:][...,None],\n",
    "    MOD17.vpd(qv10m, ps, tmean_vpd)[...,None],\n",
    "    MOD17.par(SWGNT)[:][...,None]\n",
    "]\n",
    "drivers_peru[2] = np.where(drivers_peru[2] < 0, 0, drivers_peru[2]) # VPD < 0 = 0\n",
    "\n",
    "# Gerando GPP a partir dos dados do bioma \"Evergreen Broadleaf Forest\" como parâmetro diretamente\n",
    "parametros = pd.read_csv('mod17_bplut/MOD17_BPLUT_CX.X_MERRA_NASA.csv')['EBF=1'].values\n",
    "\n",
    "parametros = [0.001405, -8.0, 9.09, 1000.0, 4000.0, 26.9, 2.0, 2.0, 1.1, 0.162, 0.00604, 0.00519, 0.00397] # Igual ao acima\n",
    "\n",
    "gpp_ebf = MOD17._gpp(parametros,drivers_peru[0],drivers_peru[1],drivers_peru[2],drivers_peru[3]) # Considerar como GPP do algorítmo\n",
    "index_peru = pd.date_range(start='2018-01-01', end='2019-12-31', freq='D')\n",
    "gpp_peru = pd.DataFrame(gpp_ebf,index= index_peru)\n",
    "gpp_peru = gpp_peru.rename_axis('index')\n",
    "gpp_peru = gpp_peru[0].rename('GPP')\n",
    "gpp_peru.to_csv('dados_calculados_torres/gpp_algpad_peru_diario.csv')\n",
    "\n",
    "np.save('dados_calculados_torres/drivers_peru', drivers_peru)\n",
    "\n",
    "peru_2018 = gpp_peru['2018'].resample('8D').sum()\n",
    "peru_2019 = gpp_peru['2019'].resample('8D').sum()\n",
    "\n",
    "gpp_peru = pd.concat([peru_2018, peru_2019], axis=0)\n",
    "\n",
    "gpp_peru.to_csv('dados_calculados_torres/gpp_algpad_peru.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drivers_peru = np.load('dados_calculados_torres/drivers_peru.npy')\n",
    "dict = {'1': np.squeeze(drivers_peru[0]), '2': np.squeeze(drivers_peru[1]), '3': np.squeeze(drivers_peru[2]), '4': np.squeeze(drivers_peru[3])} \n",
    "df_drivers_peru = pd.DataFrame(dict, index=index_peru)\n",
    "\n",
    "drivers_peru_mes = []\n",
    "for i in range(12):\n",
    "    mes = df_drivers_peru[df_drivers_peru.index.month == i+1].to_numpy().T\n",
    "    drivers_peru_mes.append(mes)\n",
    "\n",
    "np.savez('dados_calculados_torres/drivers_peru_mes',    drivers_peru_mes[0], \n",
    "                                                        drivers_peru_mes[1],\n",
    "                                                        drivers_peru_mes[2],\n",
    "                                                        drivers_peru_mes[3],\n",
    "                                                        drivers_peru_mes[4],\n",
    "                                                        drivers_peru_mes[5],\n",
    "                                                        drivers_peru_mes[6],\n",
    "                                                        drivers_peru_mes[7],\n",
    "                                                        drivers_peru_mes[8],\n",
    "                                                        drivers_peru_mes[9],\n",
    "                                                        drivers_peru_mes[10],\n",
    "                                                        drivers_peru_mes[11])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caxiuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cax = pd.read_csv('dados/Ameriflux/caxiuana/GEPCAX.txt', delimiter='\\t')\n",
    "cax['ano2'] = cax['ano2'].apply(lambda x:str(int(x)))\n",
    "cax['dia2'] = cax['dia2'].apply(lambda x:str(int(x)))\n",
    "cax['datetime'] = cax['ano2'] + cax['dia2']\n",
    "cax.index =  cax['datetime'].apply(lambda x:datetime.strptime(str(x), '%Y%j'))\n",
    "\n",
    "observacoes_cax = cax['GEP']\n",
    "observacoes_cax = observacoes_cax.rename_axis('index')\n",
    "observacoes_cax = observacoes_cax.rename('GPP')\n",
    "\n",
    "observacoes_cax.to_csv('dados_calculados_torres/observacoes_caxiuana_diario.csv')\n",
    "\n",
    "cax_2005 = observacoes_cax['2005'].resample('8D').sum()\n",
    "cax_2006 = observacoes_cax['2006'].resample('8D').sum()\n",
    "cax_2007 = observacoes_cax['2007'].resample('8D').sum()\n",
    "cax_2008 = observacoes_cax['2008'].resample('8D').sum()\n",
    "\n",
    "observacoes_cax = pd.concat([cax_2005, cax_2006, cax_2007, cax_2008], axis=0)\n",
    "\n",
    "observacoes_cax.to_csv('dados_calculados_torres/observacoes_caxiuana.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "Gpp_mod = pd.read_csv('dados/MODIS/GPP/Caxiuana_GPP.csv', header=None, na_values='F') # unidade: (%)\n",
    "Gpp_mod.index = Gpp_mod[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "Gpp_mod = Gpp_mod.drop([0,1,2,3,4], axis=1)\n",
    "Gpp_mod.columns = range(len(Gpp_mod.columns))\n",
    "Gpp_mod = Gpp_mod[144].to_frame().rename(columns={144:'Gpp_modis'})\n",
    "caxiuana_gpp_mod = Gpp_mod['2005':'2008'] * 0.0001 * 1000\n",
    "mod17_caxiuana = caxiuana_gpp_mod['Gpp_modis']\n",
    "mod17_caxiuana = mod17_caxiuana.rename_axis('index')\n",
    "mod17_caxiuana = mod17_caxiuana.rename('GPP')\n",
    "mod17_caxiuana.to_csv('dados_calculados_torres/gpp_modis_caxiuana.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor_2(path):\n",
    "    nome = path.split('/')[1].split('_')[0]\n",
    "    df = pd.read_csv(path, parse_dates=['date'])\n",
    "    df = df.rename({'albedo':nome},axis=1)\n",
    "    # Definindo a coluna 'system:time_start' como índice\n",
    "    hora_inicio = df['date'].min().floor('d')\n",
    "    df.index = hora_inicio + pd.to_timedelta(df.index, unit='h')\n",
    "    # Removendo a coluna 'system:time_start'\n",
    "    df = df.drop(['date','.geo'], axis=1)\n",
    "    df = df.drop('system:index',axis=1)\n",
    "    return df\n",
    "\n",
    "# Leitura e pré-processamento dos dados de temperatura\n",
    "tday = constructor_2('dados/Merra/caxiuana/cax_t10m.csv') - 273.15 #( K° -> C°)\n",
    "tday = tday['2005':'2008']\n",
    "tmin = tday['T10M'].resample('D').min().values  # Reamostrando para Temperatura mínima diária\n",
    "tmean_caxiuana = tday['T10M'].resample('D').mean().values  # Temperatura média diária\n",
    "tmean_vpd = tday['T10M'].between_time('10:00', '22:00').resample('D').mean().values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de razão de mistura de vapor de água\n",
    "qv10m = constructor_2('dados/Merra/caxiuana/cax_qv10m.csv') # unidade: \"Mass fraction\" (kg/kg)\n",
    "qv10m = qv10m['2005':'2008']\n",
    "qv10m = pd.to_numeric(qv10m['QV10M']).between_time('10:00', '22:00').resample('D').mean().values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de pressão atmosférica\n",
    "ps = constructor_2('dados/Merra/caxiuana/cax_ps.csv') # unidade: Pa  # Removendo vírgulas dos valores\n",
    "ps = ps['2005':'2008']\n",
    "ps['PS'] = pd.to_numeric(ps['PS'])\n",
    "ps = ps.between_time('10:00', '22:00').resample('D').mean()\n",
    "ps = pd.to_numeric(ps['PS']).values\n",
    "\n",
    "# Leitura e pré-processamento dos dados de radiação solar incidente\n",
    "SWGNT = constructor_2('dados/Merra/caxiuana/cax_swgnt.csv')\n",
    "SWGNT = SWGNT['2005':'2008']\n",
    "SWGNT = SWGNT['SWGNT'].resample('D').mean().values # unidade: W/m^2\n",
    "\n",
    "# Função para converter datas no formato MODIS\n",
    "def modis_date(data_str):\n",
    "    ano = int(data_str[1:5])\n",
    "    dia_ano = int(data_str[5:])\n",
    "    data = datetime.strptime('{}-{}'.format(ano, dia_ano), '%Y-%j')\n",
    "    return data\n",
    "\n",
    "# Leitura e pré-processamento dos dados de Fração de Absorção de Luz Fotossinteticamente Ativa (FPAR)\n",
    "fpar = pd.read_csv('dados/Merra/caxiuana/cax_fpar.csv', header=None,na_values='F') # unidade: (%)\n",
    "fpar.index = fpar[2].apply(modis_date)  # Convertendo a data no formato MODIS\n",
    "\n",
    "# Arrumando o dataframe\n",
    "# ================================\n",
    "fpar = fpar.drop([0,1,2,3,4], axis=1)\n",
    "fpar.columns = range(len(fpar.columns))\n",
    "fpar = fpar[144]\n",
    "\n",
    "# ================================\n",
    "\n",
    "# Tratamento de dados faltando usando interpolação linear (8 dias -> diário)\n",
    "fpar = fpar.resample('D').interpolate('linear')['2005':'2008']\n",
    "\n",
    "fpar = fpar.values\n",
    "\n",
    "drivers_caxiuana = [\n",
    "    fpar[:][...,None],\n",
    "    tmin[:][...,None],\n",
    "    MOD17.vpd(qv10m, ps, tmean_vpd)[...,None],\n",
    "    MOD17.par(SWGNT)[:][...,None]\n",
    "]\n",
    "drivers_caxiuana[2] = np.where(drivers_caxiuana[2] < 0, 0, drivers_caxiuana[2]) # VPD < 0 = 0\n",
    "\n",
    "# Gerando GPP a partir dos dados do bioma \"Evergreen Broadleaf Forest\" como parâmetro diretamente\n",
    "parametros = pd.read_csv('mod17_bplut/MOD17_BPLUT_CX.X_MERRA_NASA.csv')['EBF=1'].values\n",
    "\n",
    "parametros = [0.001405, -8.0, 9.09, 1000.0, 4000.0, 26.9, 2.0, 2.0, 1.1, 0.162, 0.00604, 0.00519, 0.00397] # Igual ao acima\n",
    "\n",
    "gpp_ebf = MOD17._gpp(parametros,drivers_caxiuana[0],drivers_caxiuana[1],drivers_caxiuana[2],drivers_caxiuana[3]) # Considerar como GPP do algorítmo\n",
    "index_caxiuana = pd.date_range(start='2005-01-01', end='2008-12-31', freq='D')\n",
    "\n",
    "gpp_caxiuana = pd.DataFrame(gpp_ebf,index=index_caxiuana)\n",
    "\n",
    "gpp_caxiuana = gpp_caxiuana.rename_axis('index')\n",
    "gpp_caxiuana = gpp_caxiuana[0].rename('GPP')\n",
    "\n",
    "gpp_caxiuana.to_csv('dados_calculados_torres/gpp_algpad_caxiuana_diario.csv')\n",
    "\n",
    "np.save('dados_calculados_torres/drivers_caxiuana', drivers_caxiuana)\n",
    "\n",
    "cax_2005 = gpp_caxiuana['2005'].resample('8D').sum()\n",
    "cax_2006 = gpp_caxiuana['2006'].resample('8D').sum()\n",
    "cax_2007 = gpp_caxiuana['2007'].resample('8D').sum()\n",
    "cax_2008 = gpp_caxiuana['2008'].resample('8D').sum()\n",
    "\n",
    "gpp_caxiuana = pd.concat([cax_2005, cax_2006, cax_2007, cax_2008], axis=0)\n",
    "\n",
    "gpp_caxiuana.to_csv('dados_calculados_torres/gpp_algpad_caxiuana.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_caxiuana = np.load('dados_calculados_torres/drivers_caxiuana.npy')\n",
    "dict = {'1': np.squeeze(drivers_caxiuana[0]), '2': np.squeeze(drivers_caxiuana[1]), '3': np.squeeze(drivers_caxiuana[2]), '4': np.squeeze(drivers_caxiuana[3])} \n",
    "df_drivers_caxiuana = pd.DataFrame(dict, index=index_caxiuana)\n",
    "\n",
    "drivers_caxiuana_mes = []\n",
    "for i in range(12):\n",
    "    mes = df_drivers_caxiuana[df_drivers_caxiuana.index.month == i+1].to_numpy().T\n",
    "    drivers_caxiuana_mes.append(mes)\n",
    "\n",
    "np.savez('dados_calculados_torres/drivers_caxiuana_mes',    drivers_caxiuana_mes[0], \n",
    "                                                            drivers_caxiuana_mes[1],\n",
    "                                                            drivers_caxiuana_mes[2],\n",
    "                                                            drivers_caxiuana_mes[3],\n",
    "                                                            drivers_caxiuana_mes[4],\n",
    "                                                            drivers_caxiuana_mes[5],\n",
    "                                                            drivers_caxiuana_mes[6],\n",
    "                                                            drivers_caxiuana_mes[7],\n",
    "                                                            drivers_caxiuana_mes[8],\n",
    "                                                            drivers_caxiuana_mes[9],\n",
    "                                                            drivers_caxiuana_mes[10],\n",
    "                                                            drivers_caxiuana_mes[11])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mai-dai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
