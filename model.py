# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k06oyMON9qOFf1FtoCLToX5F4JOnnvRJ

#### Bibliotecas
"""

from datetime import datetime
from time import time
from contextlib import contextmanager
from typing import List, Union
import pathlib
import os
import torch
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr,kruskal
from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score
from tsai.all import *
import optuna
from optuna.integration import FastAIPruningCallback

os.environ["DEVICE"] = "cuda"

"""### Carregando os dados"""

set_seed(1, False)
@contextmanager
def cwd(path: str) -> None:

    """
    Context manager para mudar o diretório de trabalho.
    Mantém o diretório original após a execução do bloc

    o de código.
    """

    oldpwd = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(oldpwd)

with cwd('dados/TrainTestVal_dataset/'):
    y_labels = pd.read_csv('y_labels.csv')['localidade']
    gpp_cax_test,gpp_peru_test,gpp_santarem_test = [pd.read_csv(f'dados_datasetTeste/{x}') for x in sorted(os.listdir('dados_datasetTeste'))]
    X_test,X_train,X_val,y_test,y_train,y_val = [np.load(data) for data in sorted([x for x in os.listdir() if not(x in ['dados_datasetTeste','y_labels.csv',".ipynb_checkpoints"])])]

X, y, splits = combine_split_data(xs=[X_train, X_val, X_test], ys=[y_train, y_val, y_test])
plot_splits(splits)

tfms = [None, TSForecasting()]
get_splits_len(splits) # [1806, 408, 408] ~= 70%,15%,15%

"""# Testes com as arquiteturas"""

archs = [
         (XCMPlus, {}),
         (ConvTranPlus, {}),
         (TSSequencerPlus, {}),      # Arquiteturas que estamos utilizando.
         (RNNPlus, {}),
         (ResNetPlus, {}),
         (InceptionTimePlus, {}),
         (TSTPlus, {}),
         (TransformerLSTMPlus, {}),
         (XceptionTimePlus, {}),
         (TransformerGRUPlus, {}),
         (PatchTST, {}),
        ]

def test_archs(epochs):
    results = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'mae_valid','rmse_valid','time'])
    i=0
    for _, (arch, k) in enumerate(archs):
        print(arch.__name__)
        learn = TSForecaster(X, y, splits=splits, path='models', tfms=tfms, batch_tfms=TSStandardize(), arch=arch, metrics=[mae,rmse],device=default_device(),loss_func=HuberLoss('mean'))
        start = time.time()
        learn.fit_one_cycle(epochs, lr_max=1e-05)
        elapsed = time.time() - start
        vals = learn.recorder.values[-1]
        results.loc[i] = [arch.__name__, k, count_parameters(learn.model), vals[0], vals[1], vals[2],vals[3], int(elapsed)]
        results.sort_values(by=['valid loss'], ascending=False, kind='stable', ignore_index=True, inplace=True)
        clear_output()
        display(results)
        i+=1
    results.to_csv(f'./dados/resultados_{epochs}_epocas.csv')

for epocas in range(100,350,50):
    test_archs(epocas)
